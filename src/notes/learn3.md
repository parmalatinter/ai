# [ニューラルネットワーク](https://ja.wikipedia.org/wiki/ニューラルネットワーク)

ニューラルネットワーク（神経網、英: neural network、略称: NN）は、脳機能に見られるいくつかの特性に類似した数理的モデルである。「マカロックとピッツの形式ニューロン」など研究の源流としては地球生物の神経系の探求であるが、その当初から、それが実際に生物の神経系のシミュレーションであるか否かについては議論があるため人工ニューラルネットワーク（artificial neural network、ANN）などと呼ばれることもある。また生物学と相互の進展により、相違点なども研究されている。

# 順伝播型ニューラルネットワーク

順伝播型ニューラルネットワーク（英語版）（フィードフォワードニューラルネットワーク、略称: FFNN）は、最初に考案された単純な構造の人工ニューラルネットワークモデルである。ネットワークにループする結合を持たず、入力ノード→中間ノード→出力ノードというように単一方向へのみ信号が伝播するものを指す。

- ### 単純パーセプトロン
     
     S層（感覚層、入力層）、A層（連合層、中間層）、R層（反応層、出力層）の3つの部分からなる。S層とA層の間はランダムに接続されている。S層には外部から信号が与えられる。A層はS層からの情報を元に反応する。R層はA層の答えに重みづけをして、多数決を行い、答えを出す。

- ### 多層パーセプトロン（たそうパーセプトロン、英: Multilayer perceptron、略称: MLP）

     順伝播型（英語版）ニューラルネットワークの一分類である。MLPは少なくとも3つのノードの層からなる。入力ノードを除けば、個々のノードは非線形活性化関数を使用するニューロンである。MLPは学習のために誤差逆伝播法（バックプロパゲーション）と呼ばれる教師あり学習手法を利用する[1][2]。その多層構造と非線形活性化関数が、MLPと線形パーセプトロンを区別している。MLPは線形分離可能ではないデータを識別できる[3]。

- ### RBFネットワーク

     誤差逆伝播法に用いられる活性化関数に放射基底関数を用いたニューラルネットワーク

- ### 自己組織化写像

     自己組織化写像はコホネンが1982年に提案した教師なし学習モデルであり、多次元データのクラスタリング、可視化などに用いられる。自己組織化マップ、コホネンマップとも呼ばれる。

- ### 畳み込みニューラルネットワーク

     畳み込みニューラルネットワークとは層間が全結合ではない順伝播型ニューラルネットワークのこと。

- ### 再帰型ニューラルネットワーク（リカレントニューラルネット、フィードバックニューラルネット）

     フィードフォワードニューラルネットと違い、双方向に信号が伝播するモデル。すべてのノードが他の全てのノードと結合を持っている場合、全結合リカレントニューラルネットと呼ぶ。

- ### 確率的ニューラルネット

     乱数による確率的な動作を導入した人工ニューラルネットワークモデル。モンテカルロ法のような統計的標本抽出手法と考えることができる。

- ### スパイキングニューラルネットワーク

     ニューラルネットワークをより生物学的な脳の働きに近づけるため、活動電位（スパイク）を重視して作られた人工ニューラルネットワークモデル。スパイクが発生するタイミングを情報と考える。ディープラーニングよりも扱える問題の範囲が広い次世代技術と言われている。ニューラルネットワークの処理は逐次処理のノイマン型コンピュータでは処理効率が低く、活動電位まで模倣する場合には処理効率がさらに低下するため、実用する際には専用プロセッサとして実装される場合が多い。

- ### 複素ニューラルネットワーク

     入出力信号やパラメータ（重み、閾値）が複素数値であるようなニューラルネットワークで活性化関数は必然的に複素関数になる[8]。